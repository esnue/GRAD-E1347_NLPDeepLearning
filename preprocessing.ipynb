{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis Allocation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esnue/ThesisAllocationSystem/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKLq9ntWGKop"
      },
      "source": [
        "# **Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqqOSnErFifL"
      },
      "source": [
        "As part of the workflow between GitHub and Google Colab, please follow these steps: \n",
        "1. Upload the [data](https://drive.google.com/drive/folders/1ExS7M2OOkbYS5Z5O9pbPbaCpSa0rhGet?usp=sharing) to a folder in your GDrive. \n",
        "2. Mount your GDrive.\n",
        "3. Set the data folder as your present working directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-JdJ7tJXPED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1f2d18-1244-4a80-b2e1-bb81a0d03a5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyIoA5EkFK8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7bf488-5782-49af-c70d-8fc690c7796e"
      },
      "source": [
        "!pwd\n",
        "%cd /content/drive/MyDrive/ThesisAllocationSystem"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/ThesisAllocationSystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aZ2PBcoKAWM"
      },
      "source": [
        "# **Convert PDF to TXT**\n",
        "\n",
        "Convert all PDF files in the current working directory to TXT files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8l5BUkKHPr_"
      },
      "source": [
        "!pip install tika"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-F6ZWwFyMu_"
      },
      "source": [
        "import os\n",
        "from tika import parser \n",
        "import re\n",
        "\n",
        "def read_pdf(pdf_file):\n",
        "\n",
        "    text = parser.from_file(pdf_file)['content']\n",
        "    non_bytes = text.encode().decode()\n",
        "    no_space = non_bytes.strip()\n",
        "    final = no_space.strip('\\n')\n",
        "    return final.encode(\"latin-1\",\"ignore\")\n",
        "\n",
        "def pdf_to_txt(folder_with_pdf, dest_folder):\n",
        "    pdf_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_with_pdf):\n",
        "        for f in files:\n",
        "            if '.pdf' in f:\n",
        "                pdf_files.append(os.path.join(root, f))\n",
        "    #print(pdf_files)\n",
        "\n",
        "    for file_ in pdf_files:\n",
        "        text_file = os.path.splitext(os.path.basename(file_))[0]+'.txt'\n",
        "        with open(os.path.join(dest_folder,text_file), 'wb') as text_f:\n",
        "            text_f.write(read_pdf(file_))\n",
        "\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf-rOj0yY5Or"
      },
      "source": [
        "pdf_to_txt('./supervisors', './supervisors-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9K3_kR0ZPc-"
      },
      "source": [
        "# Warning: This will run a couple minutes\n",
        "pdf_to_txt('./train-papers', './train-papers-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5FJ_Lp5Y656"
      },
      "source": [
        "pdf_to_txt('./test-theses', './test-theses-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiseIwIkY67g"
      },
      "source": [
        "pdf_to_txt('./test-proposals', './test-proposals-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-y9-PCXFzyR"
      },
      "source": [
        "# **Put TXT files into CSV**\n",
        "\n",
        "After importing the packages, define the directory of interest and run the function below to create a CSV files that entails all TXT files in the following structure: character values in columns `FileName` and `Content`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My5iltPWpLwl"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBm1nsG-5M0G"
      },
      "source": [
        "def txt_to_csv(input_dir, output_dir, new_filename): \n",
        "  \n",
        "  files = glob('/content/drive/MyDrive/ThesisAllocationSystem/' + input_dir + '/*.txt')\n",
        "  data = [[i, open(i, 'rb').read()] for i in files]\n",
        "  df = pd.DataFrame(data, columns = ['FileName', 'Content'])\n",
        "  df['FileName'] = df['FileName'].str.replace('/content/drive/MyDrive/ThesisAllocationSystem/' + input_dir + '/', '')\n",
        "  df['Content'] = df['Content'].str.slice(start = 0, stop = 32767) # Upper limit of strings per cell in csv\n",
        "  df.to_csv(output_dir + '/' + new_filename + '.csv', index = False)\n",
        "  if not df.empty: \n",
        "    print('Succesfully converted txt files in directory ' + os.path.basename('/content/drive/MyDrive/ThesisAllocationSystem/' + input_dir + ' to single csv file.'))\n",
        "  else: \n",
        "    print('File empty.') \n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxRTYK5PlzZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a94cb59-1488-4c2b-cc9e-29ad4f5e15b3"
      },
      "source": [
        "# Warning: This will take a couple minutes\n",
        "txt_to_csv('train-papers-txt', 'data_final', 'train-papers-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory train-papers-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX1nEDwsG4bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c1d5d5-d8b5-4afc-af09-484a29c129e3"
      },
      "source": [
        "txt_to_csv('test-theses-txt', 'data_final', 'test-theses-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory test-theses-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJjMMlJ17Erx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e644fbac-778a-428b-fed6-4abd3096af55"
      },
      "source": [
        "txt_to_csv('test-proposals-txt', 'data_final', 'test-proposals-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory test-proposals-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBZ_HTKUOHDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93338d23-ff5d-40fb-c1bc-3201e1d8e5e0"
      },
      "source": [
        "txt_to_csv('supervisors-txt', 'data_final', 'supervisors-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory supervisors-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMN3TWCFre-0"
      },
      "source": [
        "# **Data Labelling: Train**\n",
        "\n",
        "We manually define a dictionary containing a categorical label for each professor, broadly describing their area of research. Thereafter, we integrate these labels into the existing train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7u3ZElrdP9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# creating prof/research categorical label\n",
        "domain_dict = {'anheier': 'non_profit',\n",
        "              'bryson': 'technology_governance',\n",
        "              'cis': 'international_security',\n",
        "              'cali': 'international_law',\n",
        "              'cingolani': 'development_studies',              \n",
        "              'costello': 'migration_law',\n",
        "              'clachsland': 'climate_sustainability',\n",
        "              'graf': 'education',\n",
        "              'hallerberg': 'fiscal_governance',\n",
        "              'hammerschmid': 'public_management',\n",
        "              'hassel': 'labour_policy',\n",
        "              'hirth': 'energy_economics',\n",
        "              'hustedt': 'public_administration',\n",
        "              'iacovone': 'development_economics',\n",
        "              'jachtenfuchs': 'european_governance',\n",
        "              'jankin': 'data_science',\n",
        "              'kayser': 'comparative_politics',\n",
        "              'kreyenfeld': 'social_policy',\n",
        "              'mair': 'strategic_management',\n",
        "              'mena': 'organisational_management',              \n",
        "              'mungiu-pippidi': 'democracy_studies',\n",
        "              'munzert': 'political_behaviour',\n",
        "              'patz': 'international_organizations',\n",
        "              'reh': 'european_politics',\n",
        "              'roemmele': 'political_communication',\n",
        "               'shaikh': 'health_economics',\n",
        "               'snower': 'macroeconomics',\n",
        "               'stockmann': 'digital_governance',\n",
        "               'traxler': 'taxation',\n",
        "               'wegrich': 'policy_process'\n",
        "\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3mFJUzgr34u",
        "outputId": "16f6cb28-fb91-4d35-e749-4ccb11e1edad"
      },
      "source": [
        "# Load train data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/train-papers-final.csv', encoding = 'latin1')\n",
        "\n",
        "# Remove FileNames from txt ending\n",
        "data[\"FileName\"] = data[\"FileName\"].str.replace('.txt$', '').str.replace('\\d+', '').str.lower().str.replace('\\W+', '')\n",
        "\n",
        "print(data.sample(10))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          FileName                                            Content\n",
            "130           cali  b'ICON (2019), Vol. 17 No. 1, 2430 doi:10.1093...\n",
            "153       costello  b\"Microsoft Word - CostelloHandbookChapter16Fe...\n",
            "611           mair  b'Entrepreneurship as a Platform for Pursuing ...\n",
            "581      cingolani  b'projText-w.indd\\n\\n\\nMANY THANKS TO\\nKathy H...\n",
            "29        roemmele  b'Scientific and subversive: The two faces of ...\n",
            "112         bryson  b'AFRL-AFOSR-UK-TR-2012-0023 \\n \\n \\n \\n \\n \\n...\n",
            "595           mair  b'Microsoft Word - DI-0636-E _PC_.doc\\n\\n\\nSee...\n",
            "347     kreyenfeld  b'Fertility reactions to the Great Recession i...\n",
            "562  mungiupippidi  b'Microsoft Word - Democracy in European Neigh...\n",
            "82          bryson  b'Improving Robot Transparency: An Investigati...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8RyLJVQsDGH",
        "outputId": "518dfc94-71fc-40ab-d0ad-c92baac44749"
      },
      "source": [
        "# Create a domain column to facilitate mapping on dictionary keys and pass labels as value\n",
        "data[\"domain\"] = data[\"FileName\"].map(domain_dict)\n",
        "print(data)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         FileName  ...             domain\n",
            "0    hammerschmid  ...  public_management\n",
            "1    hammerschmid  ...  public_management\n",
            "2    hammerschmid  ...  public_management\n",
            "3    hammerschmid  ...  public_management\n",
            "4    hammerschmid  ...  public_management\n",
            "..            ...  ...                ...\n",
            "806       wegrich  ...     policy_process\n",
            "807       wegrich  ...     policy_process\n",
            "808       wegrich  ...     policy_process\n",
            "809       wegrich  ...     policy_process\n",
            "810       wegrich  ...     policy_process\n",
            "\n",
            "[811 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V61bparZsOGW",
        "outputId": "feb7efe1-ffbd-48f6-c457-97d8ea3df995"
      },
      "source": [
        "# Create binary dummy one-hot encoder for each research domain label\n",
        "dum_df = pd.get_dummies(data, columns=[\"domain\"])\n",
        "type(dum_df['domain_comparative_politics'].iloc[1])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmYtmIBMsmFb"
      },
      "source": [
        "# concate the two dataframes \n",
        "data = pd.concat([data.iloc[:,:2], dum_df.iloc[:,2:]], axis = 1)\n",
        "\n",
        "# Extract label\n",
        "dat_label = data.drop_duplicates('FileName')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HvNan7fprh7"
      },
      "source": [
        "data.drop(['FileName'], inplace=True, axis=1)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKsy0IgnpzPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b3736e-a05d-4838-badb-c95fa9d893b3"
      },
      "source": [
        "train_df = pd.DataFrame()\n",
        "train_df['content'] = data['Content']\n",
        "train_df['labels'] = data.iloc[:, 1:].values.tolist()\n",
        "\n",
        "# Check type \n",
        "print(train_df.sample(10))\n",
        "print(type(train_df['labels'].iloc[1]))\n",
        "print(type(train_df['labels'].iloc[1][1]))\n",
        "train_df.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               content                                             labels\n",
            "1    b'2007 EGPA_paper1109.doc\\n\\n\\nSee discussions...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "51   b'Artificial intelligence for the public secto...  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "113  b'Robio_final2_Joanna.pdf\\n\\n\\nLearning Motion...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "241  b'Transnational skills development in post-ind...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "766  b'Compliance Behavior in Networks: Evidence fr...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "123  b'Hard Protection through Soft Courts? Non-Ref...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
            "135  b'untitled\\n\\n\\nALL YOU NEED IS TIME? DISCREPA...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
            "316  b'SAQ114_1_14Wagner_Fpp.indd\\n\\n\\nA G A I N S ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
            "550  b'Deconstructing Balkan particularism: the amb...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "802  b\"ejrr_2015_03-009.pdf\\n\\n\\nEJRR 3|2015 369Spe...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "<class 'list'>\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(811, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWRFs0Cmznkn"
      },
      "source": [
        "# Save labeled dataframe as csv \n",
        "train_df.to_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/train-papers-label.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Fy2h8v71jj"
      },
      "source": [
        "# **Extract labelled data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_FoXIu26Ti"
      },
      "source": [
        "dat_label.drop(['Content'], inplace = True, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW1LdmkQ2edP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edca8e1a-bac2-48ef-f085-771dca9d6c7e"
      },
      "source": [
        "label_df = pd.DataFrame(dat_label)\n",
        "label_df['labels'] = label_df.iloc[:, 1:].values.tolist()\n",
        "print(label_df.sample(5))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          FileName  ...                                             labels\n",
            "546  mungiupippidi  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "746      stockmann  ...  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "634        munzert  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "340     kreyenfeld  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "577      cingolani  ...  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "\n",
            "[5 rows x 30 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgXqHD5eP1n8"
      },
      "source": [
        "# **Data Labelling: Test**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfwU0NX5QDCy"
      },
      "source": [
        "In this section, we assign the newly created labels to student thesis proposals, either referring to their first or second preference. The finished data set will serve as a validation/test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mW4Pnb-QV4e"
      },
      "source": [
        "# Load test data\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/test-proposals-final.csv', encoding = 'latin1')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkiOytkQiHW"
      },
      "source": [
        "# creating prof/research categorical label\n",
        "domain_dict2 = {'thesisproposal1': 'munzert',\n",
        "                'thesisproposal2': 'traxler',\n",
        "                'thesisproposal3': 'bryson',\n",
        "                'thesisproposal4': 'shaikh',\n",
        "                'thesisproposal5': 'munzert',\n",
        "                'thesisproposal6': 'iacovone'\n",
        "}"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0mXqAxBZpg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b39a88-0454-4531-e001-23410954141d"
      },
      "source": [
        "# Clean file names\n",
        "data_test[\"FileName\"] = data_test[\"FileName\"].str.replace(r'.txt$', '').str.lower()\n",
        "\n",
        "# Add new column: domain\n",
        "data_test[\"FileName\"] = data_test[\"FileName\"].map(domain_dict2)\n",
        "data_test2 = pd.merge(data_test, label_df, on='FileName')\n",
        "\n",
        "# Create test data frame\n",
        "test_df = pd.DataFrame()\n",
        "test_df['content'] = data_test2['Content']\n",
        "test_df['labels'] = data_test2.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Check type\n",
        "print(test_df)\n",
        "test_df.shape\n",
        "print(type(test_df['labels'].iloc[1]))\n",
        "print(type(test_df['labels'].iloc[1][1]))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             content                                             labels\n",
            "0  b'Anabel Berj\\xf3n S\\xe1nchez \\n\\n \\n\\nPROPOSA...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "1  b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "2  b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "3  b\"New Thesis Proposal Form \\n\\nAY 2019-2020 \\n...  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "4  b'Thesis Proposal \\n\\nCitizen Perceptions and ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "5  b'New Thesis Proposal Form \\n\\nAY 2020-2021 \\n...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
            "<class 'list'>\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1zavpTsQnXx"
      },
      "source": [
        "# Save df\n",
        "test_df.to_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/test-proposals-label.csv', index = False)"
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}