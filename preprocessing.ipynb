{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis Allocation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esnue/ThesisAllocationSystem/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKLq9ntWGKop"
      },
      "source": [
        "# **Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqqOSnErFifL"
      },
      "source": [
        "As part of the workflow between GitHub and Google Colab, please follow these steps: \n",
        "1. Upload the [data](https://drive.google.com/drive/folders/1ExS7M2OOkbYS5Z5O9pbPbaCpSa0rhGet?usp=sharing) to a folder in your GDrive. \n",
        "2. Mount your GDrive.\n",
        "3. Set the data folder as your present working directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-JdJ7tJXPED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca4e3d9-a845-43e9-d476-5bc48e5a3468"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyIoA5EkFK8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c904a6-88e0-41ad-926c-c48fcf7f78f1"
      },
      "source": [
        "!pwd\n",
        "%cd /content/drive/MyDrive/ThesisAllocationSystem"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ThesisAllocationSystem\n",
            "/content/drive/MyDrive/ThesisAllocationSystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aZ2PBcoKAWM"
      },
      "source": [
        "# **Convert PDF to TXT**\n",
        "\n",
        "Convert all PDF files in the current working directory to TXT files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8l5BUkKHPr_",
        "outputId": "5be46502-101d-4c88-c155-9979bd171037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tika"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (54.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp37-none-any.whl size=32885 sha256=2d87280173725727507f9b2613fca55f2c992896dd4545a12145c8bed2da8442\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-F6ZWwFyMu_"
      },
      "source": [
        "import os\n",
        "from tika import parser \n",
        "import re\n",
        "\n",
        "def read_pdf(pdf_file):\n",
        "\n",
        "    text = parser.from_file(pdf_file)['content']\n",
        "    non_bytes = text.encode().decode()\n",
        "    no_space = non_bytes.strip()\n",
        "    final = no_space.strip('\\n')\n",
        "    return final.encode(\"latin-1\",\"ignore\")\n",
        "\n",
        "def pdf_to_txt(folder_with_pdf, dest_folder):\n",
        "    pdf_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_with_pdf):\n",
        "        for f in files:\n",
        "            if '.pdf' in f:\n",
        "                pdf_files.append(os.path.join(root, f))\n",
        "    #print(pdf_files)\n",
        "\n",
        "    for file_ in pdf_files:\n",
        "        text_file = os.path.splitext(os.path.basename(file_))[0]+'.txt'\n",
        "        with open(os.path.join(dest_folder,text_file), 'wb') as text_f:\n",
        "            text_f.write(read_pdf(file_))\n",
        "\n",
        "    return None"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf-rOj0yY5Or"
      },
      "source": [
        "pdf_to_txt('./supervisors', './supervisors-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9K3_kR0ZPc-"
      },
      "source": [
        "# Warning: This will run a couple minutes\n",
        "pdf_to_txt('./train-papers', './train-papers-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5FJ_Lp5Y656"
      },
      "source": [
        "pdf_to_txt('./test-theses', './test-theses-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiseIwIkY67g"
      },
      "source": [
        "pdf_to_txt('./test-proposals', './test-proposals-txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-y9-PCXFzyR"
      },
      "source": [
        "# **Put TXT files into CSV**\n",
        "\n",
        "After importing the packages, define the directory of interest and run the function below to create a CSV files that entails all TXT files in the following structure: character values in columns `FileName` and `Content`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My5iltPWpLwl"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBm1nsG-5M0G"
      },
      "source": [
        "def txt_to_csv(input_dir, output_dir, new_filename): \n",
        "  \n",
        "  files = glob('/content/drive/MyDrive/ThesisAllocationSystem/' + input_dir + '/*.txt')\n",
        "  data = [[i, open(i, 'rb').read()] for i in files]\n",
        "  df = pd.DataFrame(data, columns = ['FileName', 'Content'])\n",
        "  df['FileName'] = df['FileName'].str.replace('/content/drive/MyDrive/ThesisAllocationSystem/' + input_dir + '/', '')\n",
        "  df['Content'] = df['Content'].str.slice(start = 0, stop = 32767) # Upper limit of strings per cell in csv\n",
        "  df.to_csv(output_dir + '/' + new_filename + '.csv', index = False)\n",
        "  if not df.empty: \n",
        "    print('Succesfully converted txt files in directory ' + os.path.basename('/content/drive/MyDrive/ThesisAllocationSystem/' + input_dir + ' to single csv file.'))\n",
        "  else: \n",
        "    print('File empty.') \n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxRTYK5PlzZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a94cb59-1488-4c2b-cc9e-29ad4f5e15b3"
      },
      "source": [
        "# Warning: This will take a couple minutes\n",
        "txt_to_csv('train-papers-txt', 'data_final', 'train-papers-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory train-papers-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX1nEDwsG4bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c1d5d5-d8b5-4afc-af09-484a29c129e3"
      },
      "source": [
        "txt_to_csv('test-theses-txt', 'data_final', 'test-theses-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory test-theses-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJjMMlJ17Erx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e644fbac-778a-428b-fed6-4abd3096af55"
      },
      "source": [
        "txt_to_csv('test-proposals-txt', 'data_final', 'test-proposals-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory test-proposals-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBZ_HTKUOHDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93338d23-ff5d-40fb-c1bc-3201e1d8e5e0"
      },
      "source": [
        "txt_to_csv('supervisors-txt', 'data_final', 'supervisors-final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesfully converted txt files in directory supervisors-txt to single csv file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMN3TWCFre-0"
      },
      "source": [
        "# **Data Labelling: Train**\n",
        "\n",
        "We manually define a dictionary containing a categorical label for each professor, broadly describing their area of research. Thereafter, we integrate these labels into the existing train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7u3ZElrdP9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# creating prof/research categorical label\n",
        "domain_dict = {'anheier': 'non_profit',\n",
        "              'bryson': 'technology_governance',\n",
        "              'cis': 'international_security',\n",
        "              'cali': 'international_law',\n",
        "              'cingolani': 'development_studies',              \n",
        "              'costello': 'migration_law',\n",
        "              'clachsland': 'climate_sustainability',\n",
        "              'graf': 'education',\n",
        "              'hallerberg': 'fiscal_governance',\n",
        "              'hammerschmid': 'public_management',\n",
        "              'hassel': 'labour_policy',\n",
        "              'hirth': 'energy_economics',\n",
        "              'hustedt': 'public_administration',\n",
        "              'iacovone': 'development_economics',\n",
        "              'jachtenfuchs': 'european_governance',\n",
        "              'jankin': 'data_science',\n",
        "              'kayser': 'comparative_politics',\n",
        "              'kreyenfeld': 'social_policy',\n",
        "              'mair': 'strategic_management',\n",
        "              'mena': 'organisational_management',              \n",
        "              'mungiu-pippidi': 'democracy_studies',\n",
        "              'munzert': 'political_behaviour',\n",
        "              'patz': 'international_organizations',\n",
        "              'reh': 'european_politics',\n",
        "              'roemmele': 'political_communication',\n",
        "               'shaikh': 'health_economics',\n",
        "               'snower': 'macroeconomics',\n",
        "               'stockmann': 'digital_governance',\n",
        "               'traxler': 'taxation',\n",
        "               'wegrich': 'policy_process'\n",
        "\n",
        "}"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3mFJUzgr34u",
        "outputId": "ffe95718-a5d7-48f8-cefd-3be467d4a00f"
      },
      "source": [
        "# Load train data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/train-papers-final.csv', encoding = 'latin1')\n",
        "\n",
        "# Remove FileNames from txt ending\n",
        "data[\"FileName\"] = data[\"FileName\"].str.replace('.txt$', '').str.replace('\\d+', '').str.lower().str.replace('\\W+', '')\n",
        "\n",
        "print(data.sample(10))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          FileName                                            Content\n",
            "445            cis  b'Information, Connectivity, and Strategic Sta...\n",
            "557  mungiupippidi  b\"Twenty Years of Postcommunism: The Other Tra...\n",
            "73          jankin  b\"Improving Public Services by Mining Citizen ...\n",
            "662          hirth  b'Reforming the electric power industry in dev...\n",
            "526           patz  b\"1 \\n \\n\\n \\n\\nBureaucratic politics and the ...\n",
            "176     flachsland  b'gle00549 128..156\\n\\n\\nPolitical Economy Det...\n",
            "97          bryson  b'Standardizing Ethical Design for Artificial ...\n",
            "765        traxler  b'Discussion Papers of the\\nMax Planck Institu...\n",
            "264        anheier  b'Managing non-profit organisations\\n\\n\\nManag...\n",
            "206     hallerberg  b'City, University of London Institutional Rep...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8RyLJVQsDGH",
        "outputId": "059105dd-c852-4edf-b523-1f148c36de22"
      },
      "source": [
        "# Create a domain column to facilitate mapping on dictionary keys and pass labels as value\n",
        "data[\"domain\"] = data[\"FileName\"].map(domain_dict)\n",
        "print(data)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         FileName  ...             domain\n",
            "0    hammerschmid  ...  public_management\n",
            "1    hammerschmid  ...  public_management\n",
            "2    hammerschmid  ...  public_management\n",
            "3    hammerschmid  ...  public_management\n",
            "4    hammerschmid  ...  public_management\n",
            "..            ...  ...                ...\n",
            "806       wegrich  ...     policy_process\n",
            "807       wegrich  ...     policy_process\n",
            "808       wegrich  ...     policy_process\n",
            "809       wegrich  ...     policy_process\n",
            "810       wegrich  ...     policy_process\n",
            "\n",
            "[811 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V61bparZsOGW",
        "outputId": "38602415-7ea0-4aa2-e3ba-0afa0b668bfe"
      },
      "source": [
        "# Create binary dummy one-hot encoder for each research domain label\n",
        "dum_df = pd.get_dummies(data, columns=[\"domain\"])\n",
        "type(dum_df['domain_comparative_politics'].iloc[1])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmYtmIBMsmFb"
      },
      "source": [
        "# concate the two dataframes \n",
        "data = pd.concat([data.iloc[:,:2], dum_df.iloc[:,2:]], axis = 1)\n",
        "\n",
        "# Extract label\n",
        "dat_label = data.drop_duplicates('FileName')"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HvNan7fprh7"
      },
      "source": [
        "data.drop(['FileName'], inplace=True, axis=1)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKsy0IgnpzPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68ed05d-0e74-442d-89e9-73d9695c1949"
      },
      "source": [
        "train_df = pd.DataFrame()\n",
        "train_df['content'] = data['Content']\n",
        "train_df['labels'] = data.iloc[:, 1:].values.tolist()\n",
        "\n",
        "# Check type and content\n",
        "print(train_df.sample(10))\n",
        "print(type(train_df['labels'].iloc[1]))\n",
        "print(type(train_df['labels'].iloc[1][1]))\n",
        "print(train_df.shape)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               content                                             labels\n",
            "11   b'Written by Nick Thijs \\nGerhard Hammerschmid...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "442  b'Understanding journalist killings\\n\\nSabine ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
            "64   b'Transfer Topic Labeling with Domain-Specific...  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "192  b'Energy transition on the rise: discourses on...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "806  b'S0017257X20000160jra 1..21\\n\\n\\nARTICLE\\n\\nT...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "246  b'Work-based higher education programmes in Ge...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "743  b\"E-Journal Article\\n\\n\\neconstor\\nMake Your P...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "520  b\"policy-brief_crossovers-VOK_ENG\\n\\n\\nWomen E...  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "608  b'DI-0521-E\\n\\n\\nWorking Paper\\n\\n* Professor ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "771  b'Nudges at the Dentist\\n\\nSteffen Altmann and...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "<class 'list'>\n",
            "<class 'int'>\n",
            "(811, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWRFs0Cmznkn"
      },
      "source": [
        "# Save labeled dataframe as csv \n",
        "train_df.to_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/train-papers-label.csv', index = False)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Fy2h8v71jj"
      },
      "source": [
        "# **Extract labelled data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_FoXIu26Ti"
      },
      "source": [
        "dat_label.drop(['Content'], inplace = True, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVpwqRBWKwmF"
      },
      "source": [
        "dat_label['labels'] = dat_label.iloc[:, 1:].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW1LdmkQ2edP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eff4dd1-6b73-445a-9873-b21e36f203d0"
      },
      "source": [
        "label_df = pd.DataFrame()\n",
        "label_df['FileName'] = dat_label['FileName']\n",
        "label_df['labels'] = dat_label['labels']\n",
        "\n",
        "# Check type\n",
        "print(type(label_df))\n",
        "print(type(label_df['labels'].iloc[1]))\n",
        "print(type(label_df['labels'].iloc[1][1]))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgXqHD5eP1n8"
      },
      "source": [
        "# **Data Labelling: Test**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfwU0NX5QDCy"
      },
      "source": [
        "In this section, we assign the newly created labels to student thesis proposals, either referring to their first or second preference. The finished data set will serve as a validation/test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mW4Pnb-QV4e"
      },
      "source": [
        "# Load test data\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/test-proposals-final.csv', encoding = 'latin1')"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkiOytkQiHW"
      },
      "source": [
        "# creating prof/research categorical label\n",
        "domain_dict2 = {'thesisproposal1': 'munzert',\n",
        "                'thesisproposal2': 'traxler',\n",
        "                'thesisproposal3': 'bryson',\n",
        "                'thesisproposal4': 'shaikh',\n",
        "                'thesisproposal5': 'munzert',\n",
        "                'thesisproposal6': 'iacovone'\n",
        "}"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0mXqAxBZpg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "8f7edb14-d603-46c2-d175-cc2bd4059602"
      },
      "source": [
        "# Clean file names\n",
        "data_test[\"FileName\"] = data_test[\"FileName\"].str.replace(r'.txt$', '').str.lower()\n",
        "\n",
        "# Add new column: domain\n",
        "data_test[\"FileName\"] = data_test[\"FileName\"].map(domain_dict2)\n",
        "\n",
        "# Merge with data label\n",
        "test_df = pd.merge(data_test, label_df, on='FileName')\n",
        "test_df['content'] = data_test['Content']\n",
        "\n",
        "# Remove non-necessary col\n",
        "test_df.drop(['FileName', 'Content'], inplace = True, axis = 1)\n",
        "\n",
        "# Swap content and labels\n",
        "cols = list(test_df.columns)\n",
        "a, b = cols.index('labels'), cols.index('content')\n",
        "cols[b], cols[a] = cols[a], cols[b]\n",
        "test_df = test_df[cols]\n",
        "\n",
        "# Check type and content\n",
        "test_df.shape\n",
        "print(type(test_df))\n",
        "print(type(test_df['labels'].iloc[1]))\n",
        "print(type(test_df['labels'].iloc[1][1]))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'Anabel Berj\\xf3n S\\xe1nchez \\n\\n \\n\\nPROPOSA...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b\"New Thesis Proposal Form \\n\\nAY 2019-2020 \\n...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'Thesis Proposal \\n\\nCitizen Perceptions and ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b'New Thesis Proposal Form \\n\\nAY 2020-2021 \\n...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content                                             labels\n",
              "0  b'Anabel Berj\\xf3n S\\xe1nchez \\n\\n \\n\\nPROPOSA...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "1  b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "2  b\"New Thesis Proposal Form \\n\\nAY 2019-2020 \\n...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "3  b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "4  b'Thesis Proposal \\n\\nCitizen Perceptions and ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "5  b'New Thesis Proposal Form \\n\\nAY 2020-2021 \\n...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1zavpTsQnXx"
      },
      "source": [
        "# Save df\n",
        "test_df.to_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/test-proposals-label.csv', index = False)"
      ],
      "execution_count": 195,
      "outputs": []
    }
  ]
}