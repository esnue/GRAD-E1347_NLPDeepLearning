{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esnue/ThesisAllocationSystem/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzDCH_RhlHCt"
      },
      "source": [
        "## **Model**\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This code script details the steps taken to develop a Transformers- and Pre-Trained based Language multi-label Text-Classification Model. \n",
        "\n",
        "The goal of the model is the ability to match students based on their thesis proposals to supervisors based on the content of their academic papers.\n",
        "\n",
        "Using academic papers as train data is an approach that was proposed by the similarly-working [Toronto Matching System](https://www.cs.toronto.edu/~zemel/documents/tpms.pdf). Instead of matching students to professors, the Toronto Matching Systems assigns Peer-Reviewers based on their academic papers to submitted papers.\n",
        "\n",
        "While thesis proposals tend to be coherent in their structure, academic papers usually have very differing structures, depending on the layout that the publisher demands. Constraining ourselves to few or one particular Journal outlet could have made the cleaning process and possibly the model training easier but would also have considerably reduced the size of the train data. \n",
        "\n",
        "Our multi-label text-classification method is based on Transformers and Pre-Trained Language Models. The Pre-Trained Mode is state-of-art [DistilBert](https://arxiv.org/abs/1910.01108). The Transformers version is [4.4.2](https://huggingface.co/transformers/).\n",
        "\n",
        "We are finetuning a pretrained DistilBERT model for multilabel text classification. This is a very common application of text classification, where a given document can be classified into one or more categories. This approach best mirrors our use case where a thesis proposal could likely be allocated to more than one research area, given the interdisciplinary nature and overlap of research areas between chairs.\n",
        "\n",
        "Before you attempt to run the script, make sure to secure the required modules and [datasets](https://drive.google.com/drive/folders/1ExS7M2OOkbYS5Z5O9pbPbaCpSa0rhGet?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Hc875clTDX"
      },
      "source": [
        "## **Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e3GrVM9lDTy",
        "outputId": "6aca1fcb-07c5-418d-b4ac-ed2a455c99e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install transformers==3.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 20.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 56.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=8c8bec69110952a9630f20a64712cbaaf7f8df17718ae8829e757082d9260e5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JhDfyvQm13A"
      },
      "source": [
        "# Import requirements\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWdtr0Jmm50S"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_wEr72pnD1y"
      },
      "source": [
        "<a id='section02'></a>\n",
        "### Importing and Pre-Processing the domain data\n",
        "\n",
        "The required data set to run this script is `train-papers-label.csv`. It can be downloaded [here](https://drive.google.com/file/d/1-12x2qro_m9HqWUEwZU_l4njMJ6y1LoX/view?usp=sharing). Please make sure you've stored it on your GDrive or on your computer.\n",
        "\n",
        "The section of the script implements the following tasks:\n",
        "\n",
        "* Load the dataset `train-papers-label.csv`\n",
        "* Tokenize the dataset\n",
        "* Transform the dataset into a DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq-DtMlBnyiU",
        "outputId": "e287bb0e-8f9e-4ecc-86ba-788a411880de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8LKOlxVoO1c"
      },
      "source": [
        "Make sure that list items are correctly stored and read as integers, not as strings, which can happen while saving a data frame as csv. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Jj-noRI7Fa"
      },
      "source": [
        "def check_form(data):\n",
        "    cols = ['content', 'labels']\n",
        "    if list(data.columns.values) == cols and (len(data['labels'].iloc[1])) == 28: \n",
        "        print('Data is in correct form.')\n",
        "    elif list(data.columns.values) != cols:\n",
        "        print('This data is not in correct form. It has to have two columns. One content column with strings, one labels column with lists of int.')\n",
        "    elif (len(data['labels'].iloc[1])) != 28:\n",
        "        print('This data is not in correct form. There must be 28 unique labels.')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bewac5D9oL6u",
        "outputId": "a8cdf9b0-e3c1-4a18-972b-fcc31886d2e8"
      },
      "source": [
        "# Load df\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/train-papers-label.csv', converters={'labels': eval})\n",
        "\n",
        "# Check content\n",
        "print(train_df.sample(10))\n",
        "check_form(train_df)\n",
        "print(type(train_df['labels'].iloc[1]))\n",
        "print(type(train_df['labels'].iloc[1][1]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               content                                             labels\n",
            "720  b'Microsoft Word - Working paper_Domestic viol...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
            "75   b\"Microsoft Word - DGHJHW_ClimateChangeConjoin...  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "359  b'Why Do Lone Mothers Fare Worse than Lone Fat...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "437  b'Repression Technology: Internet Accessibilit...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
            "144  b'Value Homophily Benefits Cooperation but Mot...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "284  b\"The Jossey-Bass Handbook of Nonprofit Leader...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "148  b'ICON (2015), Vol. 13 No. 4, 901922 doi:10.10...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
            "124  b'RSCAS 2019/43rev.3 Legal Trajectories of Neo...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
            "763  b'Beyond Regulation: Approaching the challenge...  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "487  b'Innovation Responses to Import Competition\\n...  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "Data is in correct form.\n",
            "<class 'list'>\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVCwOHqIf2D",
        "outputId": "81b6bd07-cf0b-44aa-c611-185d80bfc1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/ThesisAllocationSystem/data_final/test-proposals-label.csv', converters={'labels': eval})\n",
        "\n",
        "# Check content & type\n",
        "check_form(test_df)\n",
        "print(test_df.sample(2))\n",
        "print(type(test_df['labels'].iloc[1]))\n",
        "print(type(test_df['labels'].iloc[1][1]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is in correct form.\n",
            "                                             content                                             labels\n",
            "1  b'Master_Thesis_Proposal\\n\\n\\nMaster Thesis Pr...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "4  b'Thesis Proposal \\n\\nCitizen Perceptions and ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "<class 'list'>\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gebxzUbBpS3W"
      },
      "source": [
        "<a id='section03'></a>\n",
        "### Preparing the Dataset and Dataloader\n",
        "\n",
        "First, we define some key variables used for training/fine tuning later on. Centrally definiting key variables will make it easier later on to adjust and test metrics for different network configurations.\n",
        "\n",
        "Next, we create a Tokenizer class alongside a DataLoader specifying how the text is pre-processed prior to sending it to the neural network and the number of batches to be sent to the neural network for training.\n",
        "\n",
        "Tokenizer and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the [docs at PyTorch](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "#### *Tokenizer* Dataset Class\n",
        "- This class is defined to accept the `tokenizer`, `dataframe` and `max_length` as input and generate tokenized output and tags to be used by the DistilBERT model for training. \n",
        "- We are using the DistilBERT tokenizer to tokenize the data in the `text` column of the dataframe.\n",
        "- The tokenizer uses the `encode_plus` method to perform tokenization and generate the necessary outputs, namely: `ids`, `attention_mask`, `token_type_ids`\n",
        "\n",
        "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/distilbert.html#distilberttokenizer)\n",
        "- `targets` is the list of categories (formerly labels) labled as `0` or `1` in the dataframe. \n",
        "- The *Tokenizer* class is used to create 2 datasets, for training and for validation.\n",
        "- *Training Dataset* is used to fine tune the model: **currently 80% of the original data, but at later stage we need to include test data from different source**\n",
        "- *Validation Dataset* is used to evaluate the performance of the model. The model has not seen this data during training. \n",
        "\n",
        "#### Dataloader\n",
        "- Dataloader is used for creating training and validation dataloader sets that enable loading data to the neural network in the defined manner. This is required due to memory constraints.  \n",
        "- Via `batch_size` and `max_len`, the DataLoader controls the amount of data loaded to the memory and passed to the neural network per turn. \n",
        "- Training and Validation dataloaders are used in the training and validation part of the flow respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8QW54O8pe2H"
      },
      "source": [
        "# Configurations\n",
        "\n",
        "# Defining key var\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "# Import DistilBert Tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC7zA4nYDGX3"
      },
      "source": [
        "class Tokenizer(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.content\n",
        "        self.targets = self.data.labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOZWsLfGDOBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9299825-86f5-4114-8cc7-9608f40a0078"
      },
      "source": [
        "# Creating the train dataset and dataloader for the neural network\n",
        "train_data = train_df.sample(frac = 1,random_state = 200)\n",
        "test_data = test_df.sample(frac = 1, random_state = 200)\n",
        "# test_data = train_df.drop(train_data.index).reset_index(drop=True)\n",
        "# train_data = train_data.reset_index(drop=True)\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = Tokenizer(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = Tokenizer(test_data, tokenizer, MAX_LEN)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN Dataset: (811, 2)\n",
            "TEST Dataset: (6, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICkvMpj3p4zW"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew_dXHaZKvah"
      },
      "source": [
        "# next(iter(training_loader))\n",
        "# next(iter(testing_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6_YPU38p_wU"
      },
      "source": [
        "<a id='section04'></a>\n",
        "### Creating the Neural Network for Fine Tuning\n",
        "\n",
        "#### Neural Network\n",
        " - We will be creating a neural network with the `DistilBERTClass`. \n",
        " - This network will have the `DistilBERT` model.  Follwed by a `Droput` and `Linear Layer`. They are added for the purpose of **Regularization** and **Classification** respectively. \n",
        " - In the forward loop, there are 2 output from the `DistilBERTClass` layer.\n",
        " - The second output `output_1` or called the `pooled output` is passed to the `Drop Out layer` and the subsequent output is given to the `Linear layer`. \n",
        " - Keep note the number of dimensions for `Linear Layer` is **28** because that is the total number of categories in which we are looking to classify our model\n",
        " - The data will be fed to the `DistilBERTClass` as defined in the dataset. \n",
        " - Final layer outputs is what will be used to calcuate the loss and to determine the accuracy of models prediction. \n",
        " - We will initiate an instance of the network called `model`. This instance will be used for training and then to save the final trained model for future inference. \n",
        " \n",
        "#### Loss Function and Optimizer\n",
        " - The Loss is defined in the next cell as `loss_fn`.\n",
        " - As defined above, the loss function used will be a combination of Binary Cross Entropy which is implemented as [BCELogits Loss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss) in PyTorch\n",
        " - `Optimizer` is defined in the next cell.\n",
        " - `Optimizer` is used to update the weights of the neural network to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeftvDhjDSPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49427ae-37f2-48ac-ba47-465083a6ca36"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class DistilBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 256)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(256, 28)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.Tanh()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "model = DistilBERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBERTClass(\n",
              "  (l1): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=256, out_features=28, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ_wI0YwDVJZ"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO49FuR9DXsW"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb9-Yr9YDZqo"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reta6H84DcJq",
        "outputId": "24a54e45-72c9-4983-8a42-34f41adbc11f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "1it [00:00,  1.46it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.7046951651573181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "2it [00:01,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:02,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:03,  1.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:05,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:05,  1.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:06,  1.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:07,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:08,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:09,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:09,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:11,  1.17s/it]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:12,  1.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "14it [00:13,  1.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "15it [00:14,  1.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "16it [00:14,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "17it [00:15,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "18it [00:16,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "19it [00:17,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "20it [00:18,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "21it [00:18,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "22it [00:19,  1.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "23it [00:20,  1.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "24it [00:20,  1.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "25it [00:21,  1.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "26it [00:22,  1.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "27it [00:23,  1.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "28it [00:23,  1.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "29it [00:24,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "30it [00:25,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "31it [00:26,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "32it [00:27,  1.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "33it [00:28,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "34it [00:28,  1.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "35it [00:29,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "36it [00:30,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "37it [00:30,  1.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "38it [00:31,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "39it [00:32,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "40it [00:33,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "41it [00:34,  1.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "42it [00:35,  1.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "43it [00:35,  1.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "44it [00:36,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "45it [00:37,  1.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "46it [00:38,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "47it [00:39,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "48it [00:39,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "49it [00:40,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "50it [00:41,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "51it [00:42,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "52it [00:42,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "53it [00:44,  1.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "54it [00:45,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "55it [00:45,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "56it [00:47,  1.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "57it [00:49,  1.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "58it [00:49,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "59it [00:50,  1.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "60it [00:51,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "61it [00:51,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "62it [00:52,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "63it [00:53,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "64it [00:54,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "65it [00:55,  1.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "66it [00:56,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "67it [00:57,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "68it [00:57,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "69it [00:58,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "70it [00:59,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "71it [01:00,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "72it [01:01,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "73it [01:01,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "74it [01:02,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "75it [01:03,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "76it [01:04,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "77it [01:05,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "78it [01:05,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "79it [01:06,  1.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "80it [01:07,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "81it [01:07,  1.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "82it [01:08,  1.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "83it [01:09,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "84it [01:10,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "85it [01:11,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "86it [01:11,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "87it [01:12,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "88it [01:13,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "89it [01:14,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "90it [01:14,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "91it [01:15,  1.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "92it [01:15,  1.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "93it [01:16,  1.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "94it [01:17,  1.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "95it [01:18,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "96it [01:19,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "97it [01:19,  1.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "98it [01:20,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "99it [01:21,  1.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "100it [01:22,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "101it [01:23,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "102it [01:24,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "103it [01:24,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "104it [01:25,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "105it [01:26,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "106it [01:27,  1.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "107it [01:28,  1.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "108it [01:29,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "109it [01:30,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "110it [01:31,  1.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "111it [01:32,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "112it [01:33,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "113it [01:33,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "114it [01:35,  1.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "115it [01:36,  1.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "116it [01:37,  1.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "117it [01:38,  1.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "118it [01:40,  1.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "119it [01:41,  1.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "120it [01:42,  1.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "121it [01:43,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "122it [01:44,  1.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "123it [01:45,  1.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "124it [01:45,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "125it [01:46,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "126it [01:47,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "127it [01:48,  1.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "128it [01:49,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "129it [01:50,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "130it [01:50,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "131it [01:51,  1.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "132it [01:52,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "133it [01:53,  1.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "134it [01:53,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "135it [01:54,  1.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "136it [01:55,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "137it [01:56,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "138it [01:57,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "139it [01:58,  1.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "140it [01:58,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "141it [01:59,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "142it [02:00,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "143it [02:01,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "144it [02:02,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "145it [02:02,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "146it [02:03,  1.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "147it [02:04,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "148it [02:05,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "149it [02:05,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "150it [02:06,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "151it [02:07,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "152it [02:08,  1.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "153it [02:09,  1.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "154it [02:10,  1.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "155it [02:11,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "156it [02:11,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "157it [02:12,  1.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "158it [02:13,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "159it [02:14,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "160it [02:14,  1.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "161it [02:15,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "162it [02:16,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "163it [02:17,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "164it [02:18,  1.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "165it [02:19,  1.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "166it [02:20,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "167it [02:20,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "168it [02:21,  1.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "169it [02:22,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "170it [02:23,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "171it [02:23,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "172it [02:24,  1.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "173it [02:25,  1.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "174it [02:26,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "175it [02:27,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "176it [02:27,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "177it [02:28,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "178it [02:29,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "179it [02:30,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "180it [02:31,  1.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "181it [02:31,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "182it [02:32,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "183it [02:33,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "184it [02:34,  1.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "185it [02:35,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "186it [02:35,  1.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "187it [02:36,  1.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "188it [02:37,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "189it [02:38,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "190it [02:39,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "191it [02:40,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "192it [02:40,  1.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "193it [02:41,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "194it [02:42,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "195it [02:43,  1.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "196it [02:44,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "197it [02:45,  1.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "198it [02:46,  1.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "199it [02:46,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "200it [02:47,  1.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "201it [02:48,  1.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "202it [02:48,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "203it [02:49,  1.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUiMOXPBs6fj"
      },
      "source": [
        "As we can see, the loss rates convert but are still pretty high. This is something we will need to work on during the next weeks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1c-jQ3yq-Ky"
      },
      "source": [
        "<a id='section06'></a>\n",
        "### Validating the Model\n",
        "\n",
        "During the validation stage we pass the unseen data(Testing Dataset) to the model. This step determines how good the model performs on the unseen data. \n",
        "\n",
        "** ANPASSEN **\n",
        "This unseen data is the 20% of `train.csv` which was seperated during the Dataset creation stage. \n",
        "During the validation stage the weights of the model are not updated. Only the final output is compared to the actual value. This comparison is then used to calcuate the accuracy of the model. \n",
        "** ANPASSEN **\n",
        "\n",
        "As defined above to get a measure of our models performance we are using the following metrics. \n",
        "- Hamming Score\n",
        "- Hamming Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV17pa-CZAnJ"
      },
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UB8UlcerEqg"
      },
      "source": [
        "def validation(testing_loader):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c48IvQmlrI-S",
        "outputId": "88c5674c-d72d-4503-8527-788b19dcd6a6"
      },
      "source": [
        "outputs, targets = validation(testing_loader)\n",
        "\n",
        "final_outputs = np.array(outputs) >=0.5"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:00, 10.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwyBV2zCrKrU",
        "outputId": "6253eae0-458a-492e-a3cc-fb1c6dfdd7a5"
      },
      "source": [
        "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
        "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
        "\n",
        "print(f\"Hamming Score = {val_hamming_score}\")\n",
        "print(f\"Hamming Loss = {val_hamming_loss}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hamming Score = 0.0\n",
            "Hamming Loss = 0.03571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pno_zqstPhm"
      },
      "source": [
        "Hamming Loss: 3 % incorrectly predicted labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SweDmI_xrN2g"
      },
      "source": [
        "<a id='section07'></a>\n",
        "### Saving the trained model for inference\n",
        "\n",
        "This is the final step in the process of fine tuning the model. \n",
        "\n",
        "The model and its vocabulary are saved locally. These files are then used to make inferences on new inputs of student research proposals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwnWF9HNrkQy"
      },
      "source": [
        "BA LINH: Ich weiß nicht wie man das Vocab speichert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zva4tkgErMve",
        "outputId": "1273b7cf-469c-45d7-d269-880abdf00d3c"
      },
      "source": [
        "# Saving the files for inference\n",
        "\n",
        "#output_model_file = 'pytorch_distilbert_papers.bin'\n",
        "#output_vocab_file = 'vocab_distilbert_papers.bin'\n",
        "\n",
        "path = F\"/content/drive/MyDrive/ThesisAllocationSystem/models/pytorch_distilbert_papers_3.bin\" \n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "#path2 = F\"/content/drive/MyDrive/ThesisAllocationSystem/models/pytorch_distilbert_papers.bin\" \n",
        "#tokenizer.save_vocabulary(output_vocab_file.state_dict(), path)\n",
        "\n",
        "#torch.save(model, output_model_file)\n",
        "#tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('Saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}